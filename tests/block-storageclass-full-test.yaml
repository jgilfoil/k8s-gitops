
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kubia-sc-claim
  labels:
    app: kubia
spec:
  storageClassName: ceph-block
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kubia-sc-claim-custom
  labels:
    app: kubia
spec:
  storageClassName: ceph-block
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20M
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
  labels:
    app: kubia
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kubia
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
      annotations:
        backup.velero.io/backup-volumes: custom
        # pre.hook.backup.velero.io/container: fsfreeze
        # pre.hook.backup.velero.io/command: '["/sbin/fsfreeze", "--freeze", "/custom"]'
        # post.hook.backup.velero.io/container: fsfreeze
        # post.hook.backup.velero.io/command: '["/sbin/fsfreeze", "--unfreeze", "/custom"]'
    spec:
      containers:
      - image: luksa/fortune
        name: html-generator
        volumeMounts:
        - name: html
          mountPath: /var/htdocs
      - image: nginx:alpine
        name: web-server
        volumeMounts:
        - name: html
          mountPath: /usr/share/nginx/html
          readOnly: true
        - name: custom
          mountPath: /custom
        ports:
        - containerPort: 80
          protocol: TCP
      volumes:
      - name: html
        persistentVolumeClaim:
          claimName: kubia-sc-claim
      - name: custom
        persistentVolumeClaim:
          claimName: kubia-sc-claim-custom
---
apiVersion: v1
kind: Service
metadata:
  name: kubia
  labels:
    app: kubia
spec:
  type: ClusterIP
  selector:
    app: kubia
  ports:
  - port: 8080
    targetPort: 80
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: kubia
  labels:
    app: kubia
  namespace: default
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-production"
    traefik.ingress.kubernetes.io/router.entrypoints: "websecure"
spec:
  ingressClassName: traefik
  rules:
    - host: "kubia.apostoli.pw"
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: kubia
                port:
                  number: 8080
  tls:
    - hosts:
        - "kubia.apostoli.pw"
      secretName: "kubia-tls"


# Restore test
# velero restore create --from-backup velero-daily-backup-20211009060050 --restore-volumes=true --include-resources pods,persistentvolumeclaims,persistentvolumes --include-namespaces default
#Delete pvc
# kubectl delete pvc kubia-sc-claim-custom
# velero restore create --from-backup velero-daily-backup-20211008060049 --restore-volumes=true --include-resources pods,persistentvolumeclaims,persistentvolumes --include-namespaces default -l app=kubia
# velero restore create --from-backup velero-daily-backup-20211013060052 --restore-volumes=true --include-namespaces default -l app=kubia
#rescale back to 1
# kubectl scale deploy kubia --replicas=1
#check restored data
# kubectl exec -it kubia-6dd697759f-b42kk --container web-server -- cat /custom/data2.txt

#check restore status
#  kubectl -n velero get podvolumerestores -l velero.io/restore-name=velero-daily-backup-20211008060049-20211010163304 -o yaml